{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETaj7dxJ3HQ8"
   },
   "source": [
    "# AI stock analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PauliusU/AI-stock-analysis/blob/master/AI-stock-analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "❗Work in progress, some cells may not work❗\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**SUMMARY AND METHODOLOGY**\n",
    "\n",
    "Project aims to use compare 3 different approaches to predict stock prices using AI and choose the best one. Two of them are based on neural networks one is a linear model.\n",
    "\n",
    "Project uses the same data set (price of Tesla shares for the last 5 years). The same dateset is used to train models with 3 different architectures:\n",
    "1. First approach is price prediction using `ARIMA (Auto Regressive Integrated Moving Average)`model. ❗ N.B. ARIMA was not used during our AI course ❗\n",
    "2. Another approach uses `LSTM (long short-term memory) neural network` — the most popular machine learning approach for stock market prediction.\n",
    "3. Final approach utilizes `GRU` network.\n",
    "\n",
    "Final comparison of each approach is done on the basis of `RMSE (root-mean-square error)`. The lower the error, the better the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section uses Yahoo Finance API to fetch share price data for the last 5 years and visualizes result in the plot."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Yahoo Finance's API wrapper\n",
    "!pip install --user yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "print(f\"yfinance version: {yf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get stock data for the last 5 years\n",
    "\n",
    "ticker = 'TSLA'\n",
    "stock_data = yf.download(ticker, start='2017-11-01', end='2022-11-01')\n",
    "print(stock_data.head())\n",
    "print(stock_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot closing price over time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title('Historical stock prices')\n",
    "plt.plot(stock_data['Close'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Closing price in USD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prepare training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To prepare data to train and test models, only the closing price would be needed. Cell below gets 80% of these data points for closing price, normalizes them, and converts them into 2D array.\n",
    "\n",
    "As we use LSTM neural network we also need to scale the data in the column ‘Close’ because the machine learning algorithm works much better with scaled than with regular data. Closing price is scaled in the range between 0 and 1. This is just the preliminary operation which we need to execute to let our model work with better efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare training set\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "close_prices = stock_data['Close']\n",
    "values = close_prices.values\n",
    "training_data_len = math.ceil(len(values) * 0.8)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(values.reshape(-1, 1))\n",
    "train_data = scaled_data[0: training_data_len, :]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i - 60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare test set\n",
    "\n",
    "test_data = scaled_data[training_data_len - 60:, :]\n",
    "x_test = []\n",
    "y_test = values[training_data_len:]\n",
    "\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i - 60:i, 0])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model#1 - ARIMA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start by fitting a VERY simple ARIMA model to forecast the next value of the stock price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "model = ARIMA(y_train, order=(5,0,1)).fit()\n",
    "forecast = model.forecast(steps=1)[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f'Real data for time 0: {y_train[len(y_train)-1]}')\n",
    "print(f'Real data for time 1: {y_test[0]}')\n",
    "print(f'Pred data for time 1: {forecast}')\n",
    "\n",
    "\n",
    "model2 = ARIMA(y_train, order=(5,0,1))\n",
    "model2_fit = model2.fit()\n",
    "yhat = model2_fit.forecast()[0]\n",
    "predictions = list()\n",
    "predictions.append(yhat)\n",
    "# calculate out of sample error\n",
    "rmse = sqrt(mean_squared_error(x_test, predictions))\n",
    "print(rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# grid search ARIMA parameters for time series\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "\t# prepare training dataset\n",
    "\ttrain_size = int(len(X) * 0.66)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\thistory = [x for x in train]\n",
    "\t# make predictions\n",
    "\tpredictions = list()\n",
    "\tfor t in range(len(test)):\n",
    "\t\tmodel = ARIMA(history, order=arima_order)\n",
    "\t\tmodel_fit = model.fit()\n",
    "\t\tyhat = model_fit.forecast()[0]\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\thistory.append(test[t])\n",
    "\t# calculate out of sample error\n",
    "\trmse = sqrt(mean_squared_error(test, predictions))\n",
    "\treturn rmse\n",
    "\n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "\tdataset = dataset.astype('float32')\n",
    "\tbest_score, best_cfg = float(\"inf\"), None\n",
    "\tfor p in p_values:\n",
    "\t\tfor d in d_values:\n",
    "\t\t\tfor q in q_values:\n",
    "\t\t\t\torder = (p,d,q)\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\trmse = evaluate_arima_model(dataset, order)\n",
    "\t\t\t\t\tif rmse < best_score:\n",
    "\t\t\t\t\t\tbest_score, best_cfg = rmse, order\n",
    "\t\t\t\t\tprint(f\"ARIMA{order} RMSE={rmse:.3f}\")\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tcontinue\n",
    "\tprint(f\"Best ARIMA{best_cfg} RMSE={best_score:.3f}\")\n",
    "\n",
    "# evaluate parameters\n",
    "# p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "p_values = [0, 1, 2]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(values, p_values, d_values, q_values)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model#2 - LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if GPU is used\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\n",
    "    f\"Number of GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "\n",
    "# Print the list of available training devices - alternative method to verify TensorFlow sees the GPU\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up LSTM network architecture\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "model_lstm = keras.Sequential()\n",
    "# 100 neurons on the first layer of LSTM\n",
    "model_lstm.add(\n",
    "    keras.layers.LSTM(100, return_sequences=True,\n",
    "                      input_shape=(x_train.shape[1], 1)))\n",
    "# 100 neurons on the second layer of LSTM\n",
    "model_lstm.add(keras.layers.LSTM(100, return_sequences=False))\n",
    "# Dense with 25 neurons\n",
    "model_lstm.add(keras.layers.Dense(25))\n",
    "# Just one neuron which is our result on the last step of the model\n",
    "model_lstm.add(keras.layers.Dense(1))\n",
    "model_lstm.summary()\n",
    "\n",
    "# Set optimizer and loss function.\n",
    "# Use optimizer ‘adam’ which is the most popular in tasks of stock price prediction\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the LSTM model\n",
    "\n",
    "# Teach model during 80 epochs (computations) with batch size on each epoch equal to 10 (1/10 of samples)\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Show progress bar with verbose=1\n",
    "model_lstm.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "predictions = model_lstm.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "print(predictions)\n",
    "rmse = np.sqrt(np.mean(predictions - y_test) ** 2)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize prices the predicted by the LSTM model\n",
    "\n",
    "data = stock_data.filter(['Close'])\n",
    "train = data[:training_data_len]\n",
    "validation = data[training_data_len:]\n",
    "validation['Predictions'] = predictions\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title('Predicted prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing price in USD')\n",
    "plt.plot(train[-200:])  # Plot last 200 entries\n",
    "plt.plot(validation[['Close', 'Predictions']])\n",
    "plt.legend(\n",
    "    ['Training prices', f'Actual prices for {ticker}', 'Predicted prices'],\n",
    "    loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model#3 - GRU"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nAIjqDuVFnfD",
    "1g3URNZWFqlj",
    "imi0dVRoUvvF",
    "AVJBBfeEv9fb",
    "kIv0qmZW5GTs",
    "v5Grl-Qf5GUg"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f5e382f1eed8daa9ac0994511ef297d7b436f72018668df1a3185f67b347eef"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "042fba73a07248b1a969f777d8f91d90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0abc5773aeda4b9386308f2a0907a388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fe9996d7f8d456e83bcbbd49c658d16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ca61547da6e40a783b00381363fcc1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a4d6d1ef76145c1a29c94e7f8501498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fe9996d7f8d456e83bcbbd49c658d16",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b91635942c2d4633aa82ca25189d7828",
      "value": 1000
     }
    },
    "87b44aa2691042fe827a440bb2bcaf4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9da1826883194b35b8e22e54ba76591c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ca61547da6e40a783b00381363fcc1d",
      "placeholder": "​",
      "style": "IPY_MODEL_0abc5773aeda4b9386308f2a0907a388",
      "value": "100%"
     }
    },
    "a115aa0b3d114452a92f4604a49327ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9da1826883194b35b8e22e54ba76591c",
       "IPY_MODEL_7a4d6d1ef76145c1a29c94e7f8501498",
       "IPY_MODEL_f2cf992ffac64e55a0bd54716f639170"
      ],
      "layout": "IPY_MODEL_87b44aa2691042fe827a440bb2bcaf4a"
     }
    },
    "a960fbbfdd8b4ecb97e5440f1f6b2917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b91635942c2d4633aa82ca25189d7828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2cf992ffac64e55a0bd54716f639170": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_042fba73a07248b1a969f777d8f91d90",
      "placeholder": "​",
      "style": "IPY_MODEL_a960fbbfdd8b4ecb97e5440f1f6b2917",
      "value": " 1000/1000 [01:44&lt;00:00,  9.76it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
