{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETaj7dxJ3HQ8"
   },
   "source": [
    "# AI stock analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PauliusU/AI-stock-analysis/blob/master/AI-stock-analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "❗Work in progress, some cells may not work❗\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**SUMMARY, GOALS AND METHODOLOGY**\n",
    "\n",
    "Project aims to use compare 3 different approaches to predict stock prices using AI and choose the best one. Two of them are based on neural networks one is a linear model.\n",
    "\n",
    "All models are trained with the same data set - price of Tesla shares for the last 5 years:\n",
    "1. First approach is price prediction using `ARIMA (Auto Regressive Integrated Moving Average)` model. ❗ N.B. ARIMA was not used during our AI course ❗\n",
    "2. Another approach uses `LSTM (Long Short-Term memory) neural network` — the most popular machine learning approach for stock market prediction.\n",
    "3. Final approach utilizes `GRU (Gated Recurrent Unit)` network.\n",
    "\n",
    "Final comparison of each approach is done on the basis of `RMSE (root-mean-square error)`. The lower the error, the better the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This section uses Yahoo Finance API to fetch share price data for the last 5 years and visualizes result in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Yahoo Finance's API wrapper\n",
    "!pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "print(f\"yfinance version: {yf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get stock data for the last 5 years\n",
    "\n",
    "ticker = 'TSLA'\n",
    "stock_data = yf.download(ticker, start='2017-11-01', end='2022-11-01')\n",
    "print(stock_data.head())\n",
    "print(stock_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot closing price over time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title('Historical stock prices')\n",
    "plt.plot(stock_data['Close'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Closing price in USD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prepare training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To prepare data to train and test models, only the closing price would be needed. Cell below gets 80% of these data points for closing price, normalizes them, and converts them into 2D array.\n",
    "\n",
    "As we use LSTM neural network we also need to scale the data in the column ‘Close’ because the machine learning algorithm works much better with scaled than with regular data. Closing price is scaled in the range between 0 and 1. This is just the preliminary operation which we need to execute to let our model work with better efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare training set\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "close_prices = stock_data['Close']\n",
    "values = close_prices.values\n",
    "\n",
    "# training_data_len = math.ceil(len(values) * 0.8)\n",
    "training_data_len = int(len(values) * 0.8)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(values.reshape(-1, 1))\n",
    "train_data = scaled_data[0: training_data_len, :]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i - 60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare test set\n",
    "\n",
    "test_data = scaled_data[training_data_len - 60:, :]\n",
    "x_test = []\n",
    "y_test = values[training_data_len:]\n",
    "\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i - 60:i, 0])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model#1 - ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's start by fitting a VERY simple ARIMA model to forecast the next value of the stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grid search ARIMA parameters for time series\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "    # prepare training dataset\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        model_fit = model.fit()\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate out of sample error\n",
    "    rmse = sqrt(mean_squared_error(test, predictions))\n",
    "    return rmse, predictions, history\n",
    "\n",
    "\n",
    "# Evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg, best_predictions, best_history, = float(\n",
    "        \"inf\"), None, list(), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p, d, q)\n",
    "                try:\n",
    "                    rmse, predictions, history = evaluate_arima_model(dataset,\n",
    "                                                                      order)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg, best_predictions, best_history = rmse, order, predictions, history\n",
    "                    print(f\"ARIMA{order} RMSE={rmse:.3f}\")\n",
    "                except:\n",
    "                    continue\n",
    "    print(f\"Best ARIMA{best_cfg} RMSE={best_score:.3f}\")\n",
    "    return best_score, best_predictions, best_history\n",
    "\n",
    "\n",
    "# Evaluate parameters\n",
    "# p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "# p_values = [0, 1, 2]\n",
    "p_values = [0]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "rmse_arima, predictions_arima, history_arima = evaluate_models(values, p_values,\n",
    "                                                               d_values,\n",
    "                                                               q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "X = values\n",
    "train_size = int(len(X) * 0.8)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "history_arima = [x for x in train]\n",
    "# pprint.pprint(train_size)\n",
    "# pprint.pprint(train)\n",
    "# pprint.pprint(test)\n",
    "# pprint.pprint(history_arima)\n",
    "\n",
    "# make predictions\n",
    "predictions_arima = list()\n",
    "for t in range(len(test)):\n",
    "    print(f\"{t}: {test[t]}\")\n",
    "    model = ARIMA(history_arima, order=(1, 0, 0))\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    predictions_arima.append(yhat)\n",
    "    history_arima.append(test[t])\n",
    "# calculate out of sample error\n",
    "rmse_arima = sqrt(mean_squared_error(test, predictions_arima))\n",
    "print(rmse_arima)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model#2 - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Set up LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if GPU is used\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\n",
    "    f\"Number of GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "\n",
    "# Print the list of available training devices - alternative method to verify TensorFlow sees the GPU\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up LSTM network architecture\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "model_lstm = keras.Sequential()\n",
    "# 100 neurons on the first layer of LSTM\n",
    "model_lstm.add(\n",
    "    keras.layers.LSTM(100, return_sequences=True,\n",
    "                      input_shape=(x_train.shape[1], 1)))\n",
    "# 100 neurons on the second layer of LSTM\n",
    "model_lstm.add(keras.layers.LSTM(100, return_sequences=False))\n",
    "# Dense with 25 neurons\n",
    "model_lstm.add(keras.layers.Dense(25))\n",
    "# Just one neuron which is our result on the last step of the model\n",
    "model_lstm.add(keras.layers.Dense(1))\n",
    "model_lstm.summary()\n",
    "\n",
    "# Set optimizer and loss function\n",
    "# Use optimizer ‘adam’ which is the most popular in tasks of stock price prediction\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the LSTM model\n",
    "\n",
    "# Teach model during 80 epochs (computations) with batch size on each epoch equal to 10 (1/10 of samples)\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Show progress bar with verbose=1\n",
    "history_lstm = model_lstm.fit(x_train, y_train, batch_size=BATCH_SIZE,\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluation of LSTM\n",
    "\n",
    "predictions_lstm = model_lstm.predict(x_test)\n",
    "predictions_lstm = scaler.inverse_transform(predictions_lstm)\n",
    "rmse_lstm = np.sqrt(np.mean(predictions_lstm - y_test) ** 2)\n",
    "print(rmse_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model#3 - GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up GRU network architecture\n",
    "\n",
    "model_gru = keras.Sequential()\n",
    "model_gru.add(keras.layers.GRU(units=50, return_sequences=True,\n",
    "                               input_shape=(x_train.shape[1], 1)))\n",
    "model_gru.add(keras.layers.GRU(units=50))\n",
    "model_gru.add(keras.layers.Dense(1))\n",
    "\n",
    "# Use the same optimizer and loss function as with LSTM\n",
    "# Use optimizer ‘adam’ which is the most popular in tasks of stock price prediction\n",
    "model_gru.compile(optimizer='adam', loss='mean_squared_error')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the GRU model\n",
    "\n",
    "# Teach model during 80 epochs (computations) with batch size on each epoch equal to 10 (1/10 of samples)\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Use the same EPOCHS and BATCH_SIZE params as in LSTM model. Show progress bar with verbose=1,\n",
    "history_gru = model_gru.fit(x_train, y_train, batch_size=BATCH_SIZE,\n",
    "                            epochs=EPOCHS, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation of GRU model\n",
    "\n",
    "predictions_gru = model_gru.predict(x_test)\n",
    "predictions_gru = scaler.inverse_transform(predictions_gru)\n",
    "rmse_gru = np.sqrt(np.mean(predictions_gru - y_test) ** 2)\n",
    "print(rmse_gru)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(np.arange(len(history_lstm.history[\"loss\"])) + 0.5,\n",
    "         history_lstm.history[\"loss\"], \"b.-\", label=\"Training loss (LSTM)\")\n",
    "plt.plot(np.arange(len(history_gru.history[\"loss\"])) + 0.5,\n",
    "         history_gru.history[\"loss\"], \"r.-\", label=\"Training loss (GRU)\")\n",
    "plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "plt.title('Learning curves')\n",
    "plt.legend(fontsize=14, loc='upper right')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize prices the predicted by all models: ARIMA, LSTM and GRU\n",
    "\n",
    "data = stock_data.filter(['Close'])\n",
    "train = data[:training_data_len]\n",
    "validation = data[training_data_len:]\n",
    "validation['Predictions_ARIMA'] = predictions_arima\n",
    "validation['Predictions_LSTM'] = predictions_lstm\n",
    "validation['Predictions_GRU'] = predictions_gru\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title('Predicted prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing price in USD')\n",
    "plt.plot(train[-200:])  # Plot last 200 entries\n",
    "plt.plot(validation[[\n",
    "    'Close',\n",
    "    'Predictions_ARIMA',\n",
    "    'Predictions_LSTM',\n",
    "    'Predictions_GRU'\n",
    "]])\n",
    "plt.legend([\n",
    "    'Training prices',\n",
    "    f'Actual prices for {ticker}',\n",
    "    'Predicted prices (ARIMA)',\n",
    "    'Predicted prices (LSTM)',\n",
    "    'Predicted prices (GRU)'\n",
    "],\n",
    "    loc='upper left',\n",
    "    fontsize=14)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nAIjqDuVFnfD",
    "1g3URNZWFqlj",
    "imi0dVRoUvvF",
    "AVJBBfeEv9fb",
    "kIv0qmZW5GTs",
    "v5Grl-Qf5GUg"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('AI-PP14-FINAL-capstone-project-WHVaE_u5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "01f62612c902e53143516165eb09ff35b6f49780ec47fdb07627af9c6b797373"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "042fba73a07248b1a969f777d8f91d90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0abc5773aeda4b9386308f2a0907a388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fe9996d7f8d456e83bcbbd49c658d16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ca61547da6e40a783b00381363fcc1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a4d6d1ef76145c1a29c94e7f8501498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fe9996d7f8d456e83bcbbd49c658d16",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b91635942c2d4633aa82ca25189d7828",
      "value": 1000
     }
    },
    "87b44aa2691042fe827a440bb2bcaf4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9da1826883194b35b8e22e54ba76591c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ca61547da6e40a783b00381363fcc1d",
      "placeholder": "​",
      "style": "IPY_MODEL_0abc5773aeda4b9386308f2a0907a388",
      "value": "100%"
     }
    },
    "a115aa0b3d114452a92f4604a49327ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9da1826883194b35b8e22e54ba76591c",
       "IPY_MODEL_7a4d6d1ef76145c1a29c94e7f8501498",
       "IPY_MODEL_f2cf992ffac64e55a0bd54716f639170"
      ],
      "layout": "IPY_MODEL_87b44aa2691042fe827a440bb2bcaf4a"
     }
    },
    "a960fbbfdd8b4ecb97e5440f1f6b2917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b91635942c2d4633aa82ca25189d7828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2cf992ffac64e55a0bd54716f639170": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_042fba73a07248b1a969f777d8f91d90",
      "placeholder": "​",
      "style": "IPY_MODEL_a960fbbfdd8b4ecb97e5440f1f6b2917",
      "value": " 1000/1000 [01:44&lt;00:00,  9.76it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
